{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[ipython notebook rich display capabilities](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, we want $ 0 \\leq h_\\theta(x) \\leq 1 $\n",
      "            \n",
      "Remember this representation:           \n",
      "$ h_\\theta = g(\\theta^Tx) $      \n",
      "          \n",
      "where:      \n",
      "$ g(z) = \\frac{1}{1 + e^{-z}} $       \n",
      "       \n",
      "So our final representation is:    \n",
      "$ g(z) = \\frac{1}{1 + e^{-\\theta^Tx}} $\n",
      "\n",
      "__this is the *sigmoid* or *logistic* function__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$ p(\\mathbf{x},\\mathbf{h}) = e^{\\mathbf{h}^T \\cdot \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{c}^T \\cdot \\mathbf{x} + \\mathbf{b}^T \\cdot \\mathbf{h} }  / Z$\n",
      "\n",
      "For $p(\\mathbf{x})$, first we take $p(\\mathbf{x},\\mathbf{h})$ and take the marginal, that is, remove dependence on $\\mathbf{h}$ by summing over all possibilities.  The partition function remains unchanged as it already sums over all possibilites of $\\mathbf{x}$ and $\\mathbf{h}$.\n",
      "\n",
      "$ p(\\mathbf{x}) = \\sum \\limits_{\\mathbf{h} \\in \\{0,1\\}^H } e^{\\mathbf{h}^T \\cdot \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{c}^T \\cdot \\mathbf{x} + \\mathbf{b}^T \\cdot \\mathbf{h} }  / Z$ \n",
      "\n",
      "We factor out the exponential of $\\mathbf{c}^T \\cdot \\mathbf{x}$ which has no dependence on $\\mathbf{h}$ in the sum along with the normalisation factor (the partition function).\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{\\mathbf{h} \\in \\{0,1\\}^H} \\exp{(\\mathbf{h}^T \\cdot \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b}^T \\cdot \\mathbf{h})}$\n",
      "\n",
      "We then make the inner product an explit sum over an index. \n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{\\mathbf{h} \\in \\{0,1\\}^H} \\exp{(\\sum\\limits_{j=1}^H h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)} $\n",
      "\n",
      "Exponentials of finite sums are finite products of exponentials, hence we can factorise again.\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{\\mathbf{h} \\in \\{0,1\\}^H} \\prod\\limits_{j=1}^H \\exp{(h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)} $\n",
      "\n",
      "We can expand the sum over values drawing from the set $\\{0,1\\}^H$ by looping over each bit starting from the outermost.  You can imagine this as a large number of nested for-loops, one for each bit. \n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{h_0 \\in \\{0,1\\}} ... \\sum \\limits_{h_H \\in \\{0,1\\}} \\prod\\limits_{j=1}^H \\exp{(h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)}$\n",
      "\n",
      "The $h_H$ value is now either $0$, in which case we get an exponential yeilding 1 times the remaining product and an expression depending on $h_H$ times the remaining product which we can then factorise the product back out of to obtain this:\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{h_0 \\in \\{0,1\\}} ... \\sum \\limits_{h_{(H-1)} \\in \\{0,1\\}} \\prod\\limits_{j=1}^{H-1} \\exp{(h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)}\\exp{(0)} + \\prod\\limits_{j=1}^{H-1} \\exp{(h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)}\\exp{(\\mathbf{W}_H \\cdot \\mathbf{x} + b_H})$\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\sum \\limits_{h_0 \\in \\{0,1\\}} ... \\sum \\limits_{h_{(H-1)} \\in \\{0,1\\}} \\prod\\limits_{j=1}^{H-1} \\exp{(h_j \\mathbf{W}_j \\cdot \\mathbf{x} + b_j h_j)} (1  + \\exp{(\\mathbf{W}_H \\cdot \\mathbf{x} + b_H}))$\n",
      "\n",
      "\n",
      "Repeat this trick for each sum from $H-1$ down to $0$.\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\times (1 + \\exp{(\\mathbf{W}_1 \\cdot \\mathbf{x} + b_1})) \\times ... \\times (1  + \\exp{(\\mathbf{W}_H \\cdot \\mathbf{x} + b_H}))$\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\prod\\limits_{j=1}^{H} (1  + \\exp{(\\mathbf{W}_j \\cdot \\mathbf{x} + b_j}))$\n",
      "\n",
      "We can then use the fact that $\\exp{(\\log{(x)})}$ is the identity function to rewrite this as:\n",
      "\n",
      "$ = e^{\\mathbf{c}^T \\cdot \\mathbf{x}} / Z \\prod\\limits_{j=1}^H \\exp{(\\log{(1  + \\exp{(\\mathbf{W}_j \\cdot \\mathbf{x} + b_j}))})}$ \n",
      "\n",
      "Again using product of exponentials is exponential of sums we can get a probability expression in terms of a free energy:\n",
      "\n",
      "$ =\\exp{(\\mathbf{c}^T \\cdot \\mathbf{x} + \\sum\\limits_{j=1}^H \\log{(1  + \\exp{(\\mathbf{W}_j \\cdot \\mathbf{x} + b_j}))} )} / Z$ \n",
      "\n",
      "\n",
      "\n",
      "$ p(\\mathbf{h}|x) = \\prod_j p(h_j | x) $ \n",
      "\n",
      "$ p(h_j = 1 | x) = \\dfrac{1}{ 1 + e^{-(\\beta_j + W_j.x)} } $  \n",
      "$ p(x|h) $\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Videos with topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import YouTubeVideo\n",
      "# https://www.youtube.com/watch?v=e0Ts_7Y6hZU\n",
      "YouTubeVideo('https://www.youtube.com/watch?v=e0Ts_7Y6hZU')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"400\"\n",
        "            height=300\"\n",
        "            src=\"https://www.youtube.com/embed/https://www.youtube.com/watch?v=e0Ts_7Y6hZU\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<IPython.lib.display.YouTubeVideo at 0xb49ca24c>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### the softmax"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}